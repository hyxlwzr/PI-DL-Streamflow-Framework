{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 必要库导入 ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils import weight_norm\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import math\n",
    "import os # 新增导入os库，用于处理文件路径\n",
    "\n",
    "# ========== 0. 全局设置 ==========\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed); np.random.seed(seed); torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark      = False\n",
    "set_seed(42)\n",
    "plt.rcParams['font.sans-serif'] = ['Microsoft YaHei']; plt.rcParams['axes.unicode_minus'] = False\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "# ========== 1. 基流分割 ==========\n",
    "def eckhardt_filter(series, BFI_max=0.80, a=0.98):\n",
    "    Q = series.values\n",
    "    b = np.zeros_like(Q); b[0] = Q[0] * BFI_max\n",
    "    n1, n2, den = (1-BFI_max)*a, (1-a)*BFI_max, 1-a*BFI_max\n",
    "    for i in range(1, len(Q)):\n",
    "        b_t = (n1 * b[i-1] + n2 * Q[i]) / den\n",
    "        b[i] = min(b_t, Q[i])\n",
    "    return b, Q - b\n",
    "\n",
    "# ========== 2. 数据加载 ==========\n",
    "# !!! 注意：请将这里的路径修改为您自己电脑上的实际文件路径 !!!\n",
    "try:\n",
    "    df = pd.read_excel(r\"D:\\dataset\\ChinaMet_洛河区域汇总\\14-21.xlsx\")\n",
    "except FileNotFoundError:\n",
    "    print(\"错误：无法在 D:\\\\dataset\\\\ChinaMet_洛河区域汇总\\\\14-21.xlsx 找到数据文件。\")\n",
    "    print(\"请在代码第49行修改为您的实际文件路径后再次运行。\")\n",
    "    # 如果找不到文件，创建一个空的DataFrame以避免后续代码报错\n",
    "    df = pd.DataFrame() \n",
    "\n",
    "if not df.empty:\n",
    "    df['Time'] = pd.to_datetime(df['Time']); df.set_index('Time', inplace=True)\n",
    "    df['Baseflow'], df['Quickflow'] = eckhardt_filter(df['Runoff'])\n",
    "    # *** 修改 1/2：不再删除 'Runoff' 列，将其保留用于最终输出 ***\n",
    "    # df.drop(columns='Runoff', inplace=True) # 此行被注释掉\n",
    "\n",
    "    # ========== 2.5 高级特征工程 ==========\n",
    "    print(\"\\n--- 开始进行高级特征工程 ---\")\n",
    "    df['pre_sum_3d']  = df['pre'].rolling(3, 1).sum()\n",
    "    df['pre_sum_7d']  = df['pre'].rolling(7, 1).sum()\n",
    "    df['pre_sum_14d'] = df['pre'].rolling(14, 1).sum()\n",
    "    df['pre_sum_30d'] = df['pre'].rolling(30, 1).sum()\n",
    "    df['SMrz_mean_14d'] = df['SMrz'].rolling(14, 1).mean()\n",
    "    df['rhu_mean_14d']  = df['rhu'].rolling(14, 1).mean()\n",
    "    df['petm_sum_14d']  = df['petm'].rolling(14, 1).sum()\n",
    "    is_rain = df['pre'] > 1.0\n",
    "    days_since_rain = is_rain.cumsum()\n",
    "    df['days_since_last_rain'] = days_since_rain.sub(days_since_rain.where(is_rain).ffill().fillna(0)).astype(int)\n",
    "    df['pre_std_7d'] = df['pre'].rolling(7, 1).std().fillna(0)\n",
    "    k = 0.9\n",
    "    api_values = np.zeros(len(df))\n",
    "    pre_values = df['pre'].values\n",
    "    for i in range(1, len(df)):\n",
    "        api_values[i] = k * api_values[i-1] + pre_values[i]\n",
    "    df['api'] = api_values\n",
    "    print(\"新增季节性特征和交互特征...\")\n",
    "    df['dayofyear'] = df.index.dayofyear\n",
    "    df['sin_doy'] = np.sin(2 * np.pi * df['dayofyear'] / 366)\n",
    "    df['cos_doy'] = np.cos(2 * np.pi * df['dayofyear'] / 366)\n",
    "    df.drop(columns='dayofyear', inplace=True)\n",
    "    df['api_x_pre_sum_3d'] = df['api'] * df['pre_sum_3d']\n",
    "    df.dropna(inplace=True)\n",
    "    print(f\"特征工程完成，处理NaN后数据从 {df.index[0]} 开始。\")\n",
    "\n",
    "# ========== 3. 数据预处理函数 ==========\n",
    "def prepare_data_for_model(df_org, target, non_lag_feats, max_lag=7, corr_thr=0.3, look_back=30, use_log=False, std_target=False):\n",
    "    data = df_org.copy()\n",
    "    if use_log: data[target] = np.log1p(data[target])\n",
    "    feats_to_lag = [c for c in df_org.columns if c not in non_lag_feats and is_numeric_dtype(df_org[c])]\n",
    "    for c in feats_to_lag:\n",
    "        for k in range(1, max_lag+1):\n",
    "            data[f\"{c}_lag{k}\"] = df_org[c].shift(k)\n",
    "    # 此处会自动丢弃原始的'Runoff'列(因为它不是target)，所以不会影响模型训练\n",
    "    data.drop(columns=[c for c in feats_to_lag if c != target], inplace=True)\n",
    "    data.dropna(inplace=True)\n",
    "    engineered = ['pre_sum_3d','pre_sum_7d','pre_sum_14d','pre_sum_30d','SMrz_mean_14d','rhu_mean_14d','petm_sum_14d','days_since_last_rain','pre_std_7d','api', 'sin_doy', 'cos_doy', 'api_x_pre_sum_3d']\n",
    "    sel = data.corr()[target].abs().pipe(lambda s: s[s>=corr_thr]).index.tolist()\n",
    "    if target not in sel: sel.append(target)\n",
    "    for f in engineered:\n",
    "        if f in data and f not in sel: sel.append(f)\n",
    "    data = data[sel]\n",
    "    X_raw, y_raw = data.drop(columns=target), data[[target]]\n",
    "    scaler_X = MinMaxScaler().fit(X_raw); X = scaler_X.transform(X_raw)\n",
    "    scaler_y = StandardScaler() if std_target else MinMaxScaler()\n",
    "    y = scaler_y.fit_transform(y_raw).flatten()\n",
    "    arr = np.hstack([X, y.reshape(-1,1)])\n",
    "    tgt_idx = arr.shape[1]-1\n",
    "    X_seq, y_seq = [], []\n",
    "    for i in range(len(arr)-look_back):\n",
    "        X_seq.append(arr[i:i+look_back]); y_seq.append(arr[i+look_back, tgt_idx])\n",
    "    X_seq = torch.tensor(np.array(X_seq), dtype=torch.float32)\n",
    "    y_seq = torch.tensor(np.array(y_seq), dtype=torch.float32).view(-1,1)\n",
    "    n = len(X_seq); n_train, n_val = int(n*0.7), int(n*0.15)\n",
    "    X_train, y_train = X_seq[:n_train], y_seq[:n_train]\n",
    "    X_val,   y_val   = X_seq[n_train:n_train+n_val], y_seq[n_train:n_train+n_val]\n",
    "    X_test,  y_test  = X_seq[n_train+n_val:], y_seq[n_train+n_val:]\n",
    "    train_loader = DataLoader(TensorDataset(X_train, y_train), 64, shuffle=True)\n",
    "    val_loader   = DataLoader(TensorDataset(X_val, y_val), 64, shuffle=False)\n",
    "    test_loader  = DataLoader(TensorDataset(X_test, y_test), 64, shuffle=False)\n",
    "    train_dates = data.index[look_back : look_back + n_train]\n",
    "    test_dates = data.index[look_back + n_train + n_val:]\n",
    "    return (train_loader, val_loader, test_loader, scaler_y, X_train.shape[2], y_test.numpy(), y_train, train_dates, test_dates)\n",
    "\n",
    "# ========== 4. 数据准备 ==========\n",
    "if not df.empty:\n",
    "    look_back = 30\n",
    "    today_feats = [c for c in ['SMrz','SMs','petm','pre','pres','rhu','tepmax','tepmin','tepmean','wind', 'sin_doy', 'cos_doy', 'api_x_pre_sum_3d'] if c in df.columns]\n",
    "    base_dl  = prepare_data_for_model(df,'Baseflow', today_feats,3,0.3,look_back,False,False)\n",
    "    (train_b,val_b,test_b,sc_b,dim_b,ytest_b,_,_,_) = base_dl\n",
    "    quick_dl = prepare_data_for_model(df,'Quickflow', today_feats,3,0.2,look_back,True,True)\n",
    "    (train_q,val_q,test_q,sc_q,dim_q,ytest_q,y_train_q, train_dates_q, test_dates_q) = quick_dl\n",
    "\n",
    "# ========== 5. 模型 & 连续加权损失 ==========\n",
    "class LSTMHead(nn.Module):\n",
    "    def __init__(self, inp, hid, layers, outp, drop):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(inp, hid, layers, batch_first=True, dropout=drop if layers > 1 else 0)\n",
    "        self.drop, self.fc = nn.Dropout(drop), nn.Linear(hid, outp)\n",
    "    def forward(self, x):\n",
    "        _, (h, _) = self.lstm(x)\n",
    "        return self.fc(self.drop(h[-1]))\n",
    "\n",
    "class CNNGRU(nn.Module):\n",
    "    def __init__(self, input_dim, cnn_out_channels, cnn_kernel_size, gru_hidden_dim, gru_num_layers, output_dim, dropout_rate):\n",
    "        super(CNNGRU, self).__init__()\n",
    "        self.conv1d = nn.Conv1d(in_channels=input_dim, \n",
    "                                out_channels=cnn_out_channels, \n",
    "                                kernel_size=cnn_kernel_size, \n",
    "                                padding=(cnn_kernel_size - 1) // 2)\n",
    "        self.gru = nn.GRU(cnn_out_channels, gru_hidden_dim, gru_num_layers,\n",
    "                          batch_first=True, dropout=dropout_rate if gru_num_layers > 1 else 0)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.fc = nn.Linear(gru_hidden_dim, output_dim)\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.conv1d(x)\n",
    "        x = F.relu(x)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        gru_out, _ = self.gru(x)\n",
    "        last_time_step_out = gru_out[:, -1, :]\n",
    "        output = self.fc(self.dropout(last_time_step_out))\n",
    "        return output\n",
    "\n",
    "class AsymmetricWeightedMSE(nn.Module):\n",
    "    def __init__(self, q_mid, q_high, q_extreme, \n",
    "                 w_mid=5.0, w_high=15.0, w_extreme=30.0, \n",
    "                 overestimation_penalty=0.7):\n",
    "        super().__init__()\n",
    "        self.q_mid, self.q_high, self.q_extreme = q_mid, q_high, q_extreme\n",
    "        self.w_mid, self.w_high, self.w_extreme = w_mid, w_high, w_extreme\n",
    "        self.overestimation_penalty = overestimation_penalty\n",
    "        self.mse = nn.MSELoss(reduction='none')\n",
    "    def forward(self, preds, targets):\n",
    "        base_weights = torch.ones_like(targets, device=targets.device)\n",
    "        base_weights[targets >= self.q_mid] = self.w_mid\n",
    "        base_weights[targets >= self.q_high] = self.w_high\n",
    "        base_weights[targets >= self.q_extreme] = self.w_extreme\n",
    "        loss = self.mse(preds, targets)\n",
    "        weighted_loss = base_weights * loss\n",
    "        asym_weights = torch.ones_like(targets, device=targets.device)\n",
    "        asym_weights[preds > targets] = self.overestimation_penalty\n",
    "        final_loss = torch.mean(asym_weights * weighted_loss)\n",
    "        return final_loss\n",
    "\n",
    "# ========== 6. 训练器 ==========\n",
    "def fit(model, loaders, crit, opt, sched, ne=150, patience=30, name=''):\n",
    "    tr,vl,best,bad = [],[],1e9,0; best_state=None\n",
    "    print(f\"\\n--- 开始训练模型: {name} (早停={patience}) ---\")\n",
    "    dev = next(model.parameters()).device\n",
    "    for ep in range(1,ne+1):\n",
    "        model.train(); s=0\n",
    "        for x,y in loaders[0]:\n",
    "            x,y=x.to(dev),y.to(dev); opt.zero_grad()\n",
    "            loss=crit(model(x),y); loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(),1.0); opt.step(); s+=loss.item()\n",
    "        tr.append(s/len(loaders[0]))\n",
    "        model.eval(); s=0\n",
    "        with torch.no_grad():\n",
    "            for x,y in loaders[1]:\n",
    "                s += crit(model(x.to(dev)), y.to(dev)).item()\n",
    "        v = s/len(loaders[1]); vl.append(v); sched.step(v)\n",
    "        if v<best: best,bad,best_state = v,0,model.state_dict()\n",
    "        else: bad+=1\n",
    "        if ep%10==0: print(f\"{name} Ep[{ep:03d}/{ne}]  tr={tr[-1]:.4e}  vl={v:.4e}\")\n",
    "        if bad>=patience: print(f\"→ 早停于 Ep {ep}\"); break\n",
    "    model.load_state_dict(best_state); model.eval(); outs=[]\n",
    "    with torch.no_grad():\n",
    "        for x,_ in loaders[2]:\n",
    "            outs.extend(model(x.to(dev)).cpu().numpy())\n",
    "    return np.array(outs)\n",
    "\n",
    "# ========== 7. 实例化 & 训练 ==========\n",
    "if not df.empty:\n",
    "    dev = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    m_base = LSTMHead(dim_b, 128, 2, 1, 0.2).to(dev)\n",
    "    opt_b  = torch.optim.Adam(m_base.parameters(), 2e-3, weight_decay=1e-5)\n",
    "    sch_b  = torch.optim.lr_scheduler.ReduceLROnPlateau(opt_b,'min',factor=0.7,patience=10)\n",
    "    pred_b = fit(m_base,(train_b,val_b,test_b),nn.MSELoss(),opt_b,sch_b, name='Baseflow_LSTM')\n",
    "    q_mid = torch.quantile(y_train_q, 0.85).item()\n",
    "    q_high = torch.quantile(y_train_q, 0.95).item()\n",
    "    q_extreme = torch.quantile(y_train_q, 0.99).item()\n",
    "    print(f\"\\nQuickflow 微雕分段阈值: q85={q_mid:.4f}, q95={q_high:.4f}, q99={q_extreme:.4f}\")\n",
    "    m_quick = CNNGRU(input_dim=dim_q, cnn_out_channels=64, cnn_kernel_size=3,\n",
    "                     gru_hidden_dim=128, gru_num_layers=2, output_dim=1, dropout_rate=0.4).to(dev)\n",
    "    opt_q   = torch.optim.Adam(m_quick.parameters(), 5e-4, weight_decay=1e-5)\n",
    "    sch_q   = torch.optim.lr_scheduler.ReduceLROnPlateau(opt_q,'min',factor=0.7,patience=10)\n",
    "    crit_q = AsymmetricWeightedMSE(q_mid, q_high, q_extreme,\n",
    "                                   w_mid=5.0, w_high=15.0, w_extreme=35.0,\n",
    "                                   overestimation_penalty=0.7).to(dev)\n",
    "    pred_q  = fit(m_quick,(train_q,val_q,test_q),crit_q,opt_q,sch_q, name='Quickflow_CNNGRU', patience=50)\n",
    "\n",
    "# ========== 8. 逆变换 & 评估 ==========\n",
    "if not df.empty:\n",
    "    def inv_transform(scaler, data):\n",
    "        if data.ndim == 1: data = data.reshape(-1, 1)\n",
    "        return scaler.inverse_transform(data)\n",
    "    def nash_sutcliffe(obs, sim):\n",
    "        return 1 - np.sum((obs - sim) ** 2) / np.sum((obs - np.mean(obs)) ** 2)\n",
    "    \n",
    "    y_b   = inv_transform(sc_b, ytest_b)\n",
    "    p_b   = inv_transform(sc_b, pred_b)\n",
    "    y_q_l = inv_transform(sc_q, ytest_q)\n",
    "    p_q_l = inv_transform(sc_q, pred_q)\n",
    "    y_q, p_q = np.expm1(y_q_l), np.expm1(p_q_l)\n",
    "    p_b[p_b<0]=0; p_q[p_q<0]=0\n",
    "    \n",
    "    print(\"\\n--- 开始独立评估各个模型组件 ---\")\n",
    "    def evaluate_component(y_true, y_pred, name=''):\n",
    "        rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "        mae = mean_absolute_error(y_true, y_pred)\n",
    "        r2 = r2_score(y_true, y_pred)\n",
    "        nse = nash_sutcliffe(y_true.flatten(), y_pred.flatten())\n",
    "        print(f\"\\n--- {name} 模型性能 ---\")\n",
    "        print(f\"RMSE = {rmse:.4f}; MAE = {mae:.4f}; R² = {r2:.4f}; NSE = {nse:.4f}\")\n",
    "        return nse\n",
    "    \n",
    "    nse_b = evaluate_component(y_b, p_b, \"基流(Baseflow)\")\n",
    "    nse_q = evaluate_component(y_q, p_q, \"快速流(Quickflow)\")\n",
    "    y_all, p_all = y_b + y_q, p_b + p_q\n",
    "    rmse = np.sqrt(mean_squared_error(y_all, p_all))\n",
    "    mae  = mean_absolute_error(y_all, p_all)\n",
    "    r2   = r2_score(y_all, p_all)\n",
    "    nse = nash_sutcliffe(y_all.flatten(), p_all.flatten())\n",
    "    print(f\"\\n--- 最终组合模型在测试集上的性能 ---\")\n",
    "    print(f\"RMSE = {rmse:.4f} ; MAE = {mae:.4f} ; R² = {r2:.4f} ; NSE = {nse:.4f}\")\n",
    "\n",
    "# ========== 9. 高级可视化 ==========\n",
    "if not df.empty:\n",
    "    import matplotlib.dates as mdates\n",
    "    plt.rc('font', family='Microsoft YaHei', size=10)\n",
    "    plt.rc('axes', unicode_minus=False)\n",
    "    plt.style.use('ggplot')\n",
    "    final_dates = test_dates_q\n",
    "    min_len = len(final_dates)\n",
    "    p_all, y_all = p_all[:min_len], y_all[:min_len]\n",
    "    fig, ax = plt.subplots(figsize=(15, 6))\n",
    "    ax.plot(final_dates, y_all, 'b-', linewidth=1.8, label='真实总径流')\n",
    "    ax.plot(final_dates, p_all, 'r-', linewidth=1.5, alpha=0.9, label='预测总径流')\n",
    "    ax.set_title(f'总径流预测结果 (RMSE={rmse:.2f}, NSE={nse:.3f})', fontsize=14, pad=12)\n",
    "    ax.set_xlabel('日期', fontsize=10); ax.set_ylabel('径流量 (mm)', fontsize=10)\n",
    "    ax.legend(loc='upper right', frameon=True, shadow=True)\n",
    "    ax.grid(True, linestyle='--', alpha=0.7)\n",
    "    textstr = f'RMSE: {rmse:.2f}\\nMAE: {mae:.2f}\\nNSE: {nse:.3f}\\nR²: {r2:.3f}'\n",
    "    props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
    "    ax.text(0.02, 0.95, textstr, transform=ax.transAxes, fontsize=10, verticalalignment='top', bbox=props)\n",
    "    plt.tight_layout(); plt.show()\n",
    "    \n",
    "    print(\"\\n--- 生成并排的可视化诊断图 ---\")\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(15, 12), sharex=True)\n",
    "    y_b_plot = y_b[:min_len]; p_b_plot = p_b[:min_len]\n",
    "    y_q_plot = y_q[:min_len]; p_q_plot = p_q[:min_len]\n",
    "    axes[0].plot(final_dates, y_all, 'b-', label='真实总径流')\n",
    "    axes[0].plot(final_dates, p_all, 'r-', alpha=0.9, label='预测总径流')\n",
    "    axes[0].set_title(f'总径流 (Overall) - NSE: {nse:.3f}', fontsize=14)\n",
    "    axes[0].set_ylabel('径流量 (mm)'); axes[0].legend(); axes[0].grid(True, linestyle='--', alpha=0.7)\n",
    "    axes[1].plot(final_dates, y_b_plot, 'b-', label='真实基流')\n",
    "    axes[1].plot(final_dates, p_b_plot, 'r-', alpha=0.9, label='预测基流')\n",
    "    axes[1].set_title(f'基流 (Baseflow) - NSE: {nse_b:.3f}', fontsize=14)\n",
    "    axes[1].set_ylabel('径流量 (mm)'); axes[1].legend(); axes[1].grid(True, linestyle='--', alpha=0.7)\n",
    "    axes[2].plot(final_dates, y_q_plot, 'b-', label='真实快速流')\n",
    "    axes[2].plot(final_dates, p_q_plot, 'r-', alpha=0.9, label='预测快速流')\n",
    "    axes[2].set_title(f'快速流 (Quickflow) - NSE: {nse_q:.3f}', fontsize=14)\n",
    "    axes[2].set_ylabel('径流量 (mm)'); axes[2].legend(); axes[2].grid(True, linestyle='--', alpha=0.7)\n",
    "    fig.autofmt_xdate(); plt.xlabel('日期'); plt.tight_layout(); plt.show()\n",
    "\n",
    "# ========== 10. 洪峰期靶向评估 ==========\n",
    "if not df.empty:\n",
    "    print(\"\\n--- 洪峰期靶向评估 ---\")\n",
    "    flood_thr = np.percentile(y_all, 95)\n",
    "    idx_flood = y_all.flatten() > flood_thr\n",
    "    if idx_flood.any():\n",
    "        flood_dates = np.array(final_dates)[idx_flood]\n",
    "        act_flood = y_all.flatten()[idx_flood]\n",
    "        pre_flood = p_all.flatten()[idx_flood]\n",
    "        flood_rmse = np.sqrt(mean_squared_error(act_flood, pre_flood))\n",
    "        flood_mae  = mean_absolute_error(act_flood, pre_flood)\n",
    "        flood_r2   = r2_score(act_flood, pre_flood)\n",
    "        flood_nse  = nash_sutcliffe(act_flood, pre_flood)\n",
    "        print(f\"阈值：Total Runoff > {flood_thr:.2f}\")\n",
    "        print(f\"Flood-RMSE = {flood_rmse:.4f} ; Flood-MAE = {flood_mae:.4f}\")   \n",
    "        print(f\"Flood-R² = {flood_r2:.4f} ; Flood-NSE = {flood_nse:.4f}\")\n",
    "    else:\n",
    "        print(\"测试集未检出超过 95% 分位的洪峰。\")\n",
    "\n",
    "\n",
    "\n",
    "# ========== 11. 保存预测结果到Excel ==========\n",
    "if not df.empty:\n",
    "    print(\"\\n--- 开始保存预测结果到Excel ---\")\n",
    "    \n",
    "    # 创建结果DataFrame\n",
    "    results_df = pd.DataFrame({\n",
    "        'time': test_dates_q,  # 使用测试集对应的时间索引\n",
    "        'prediction': p_all.flatten(),  # 组合预测结果（基流+快速流）\n",
    "        'true': y_all.flatten()  # 组合真实值（基流+快速流）\n",
    "    })\n",
    "    \n",
    "    # 确保保存路径存在\n",
    "    save_path = r\"C:\\Users\\李\\Desktop\\论文\\分析3\"\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    # 计算并显示一些基本统计信息\n",
    "    print(\"\\n保存数据的统计信息:\")\n",
    "    print(f\"预测值范围: {results_df['prediction'].min():.4f} - {results_df['prediction'].max():.4f}\")\n",
    "    print(f\"真实值范围: {results_df['true'].min():.4f} - {results_df['true'].max():.4f}\")\n",
    "    print(f\"时间范围: {results_df['time'].min()} 到 {results_df['time'].max()}\")\n",
    "    \n",
    "    # 可选：同时保存分解后的各个组件\n",
    "    detailed_results_df = pd.DataFrame({\n",
    "        'time': test_dates_q,\n",
    "        'baseflow_prediction': p_b.flatten(),\n",
    "        'baseflow_true': y_b.flatten(),\n",
    "        'quickflow_prediction': p_q.flatten(),\n",
    "        'quickflow_true': y_q.flatten(),\n",
    "        'total_prediction': p_all.flatten(),\n",
    "        'total_true': y_all.flatten()\n",
    "    })\n",
    "    \n",
    "    # 保存详细分解结果\n",
    "    detailed_excel_path = os.path.join(save_path, \"LSTM-CNN+GRU （分解）_详细.xlsx\")\n",
    "    detailed_results_df.to_excel(detailed_excel_path, index=False)\n",
    "    print(f\"\\n详细分解结果已保存到: {detailed_excel_path}\")\n",
    "    \n",
    "else:\n",
    "    print(\"数据为空，无法保存结果。\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
